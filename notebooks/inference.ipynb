{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec1d8d9-bfcc-4db1-89fd-50634edced09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P40'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031f731d-12ff-4db7-8ea4-8aeec97dd72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8599540e-ef35-4d70-a9b7-31c17575e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 9082\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1135\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1136\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_name = \"locchh/nvidia_qa\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01102d61-0aeb-434f-b151-d45ce07912f5",
   "metadata": {},
   "source": [
    "## meta-llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0cd94-87da-447e-92a1-b308afa12c54",
   "metadata": {},
   "source": [
    "3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5d1e8d-f2a2-413c-9255-d32b5f8a1a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c839f16f58b4b7bb935ad952e39a129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load models\n",
    "\n",
    "pipe_llama_3B = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db33ed5a-c546-45a7-ae8f-82a8fcff6558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " Where can you find more CUDA programming resources? \n",
      "\n",
      "Output:\n",
      "You can find more CUDA programming resources on official NVIDIA websites, such as the CUDA Toolkit documentation, the NVIDIA Developer website, and online forums like the NVIDIA Developer Forum and Stack Overflow. \n",
      "\n",
      "Answer:\n",
      " The NVIDIA Developer Blog and NVIDIA Deep Learning Institute (DLI) offer further resources for learning CUDA programming and related topics.\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]\n",
    "\n",
    "outputs = pipe_llama_3B(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf264644-1368-4294-93c5-9942e93a6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does the CUDA programming model simplify the task of parallel programming? \n",
      "\n",
      "Output:\n",
      "The CUDA programming model simplifies the task of parallel programming by providing a structured approach to parallel computing, allowing developers to write efficient, thread-level parallel code that can be executed on NVIDIA's GPU architecture. \n",
      "\n",
      "Answer:\n",
      " The CUDA programming model simplifies parallel programming by allowing developers to express parallelism using familiar constructs like loops and function calls.\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]\n",
    "\n",
    "outputs = pipe_llama_3B(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff345d9-d75d-4e91-91f1-acb51a472a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How are event consumers able to subscribe to callbacks? \n",
      "\n",
      "Output:\n",
      "Event consumers are able to subscribe to callbacks by registering a callback function with the event producer or event dispatcher, which then invokes the callback function when a specific event occurs. \n",
      "\n",
      "Answer:\n",
      " Subscription functions create the ISubscription class, which usually unsubscribes automatically upon destruction.\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]\n",
    "\n",
    "outputs = pipe_llama_3B(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce40ba-3243-4fa5-afc9-44d739b6a883",
   "metadata": {},
   "source": [
    "1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4270224-74f6-47b6-8f37-69eca13bc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "pipe_llama_1B = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1385963f-59bb-46a6-9aa3-bdff16c1013d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " What is the primary purpose of CUDA? \n",
      "\n",
      "Output:\n",
      "The primary purpose of CUDA (Compute Unified Device Architecture) is to provide a high-performance, parallel computing platform for developing and executing applications on multi-core, multi-processor graphics processing units (GPUs). \n",
      "\n",
      "Answer:\n",
      " The primary purpose of CUDA is to enable parallel computing on NVIDIA GPUs (Graphics Processing Units).\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]\n",
    "\n",
    "outputs = pipe_llama_1B(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c70fce-58c8-478a-ac86-d9d3741b72e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " What is the purpose of the shuffle (SHFL) instruction on the Kepler GPU architecture? \n",
      "\n",
      "Output:\n",
      "The SHFL instruction on the Kepler GPU architecture is used for single-threaded memory access and data transfer between registers and memory, allowing for efficient data movement and caching. \n",
      "\n",
      "Answer:\n",
      " The shuffle instruction allows threads within a warp to exchange or broadcast data directly without using shared memory. It facilitates efficient parallel reductions and data exchange among threads in the same warp.\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]\n",
    "\n",
    "outputs = pipe_llama_1B(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83c17a-fbb2-40d6-8595-4db871f19a30",
   "metadata": {},
   "source": [
    "## SmolLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26597f0-186c-4d57-bd75-de5212598d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "pipe_smol_135M = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"HuggingFaceTB/SmolLM-135M-Instruct\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "pipe_smol_360M = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"HuggingFaceTB/SmolLM-360M-Instruct\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "pipe_smol_1700M = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"HuggingFaceTB/SmolLM-1.7B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be76511-8610-4e7b-b148-129b1eac80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_new_tokens=50\n",
    "\n",
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c39ac9-9105-41c2-a45e-6f9fa91ba433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does the rule system in Nsight Compute contribute to the analysis process? \n",
      "\n",
      "Output:\n",
      "The rule system in Nsight Compute is a complex and multifaceted system that plays a crucial role in the analysis process. Here are some ways it contributes to the analysis:\n",
      "\n",
      "1. **Data Integration**: The rule system is designed to integrate and analyze large \n",
      "\n",
      "Answer:\n",
      " The rule system in Nsight Compute provides instructions to the profiler for collecting metrics and displaying results, guiding the analysis process by highlighting performance bottlenecks.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_135M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3bd821-f8db-4d66-a88f-ea51282e5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does the rule system in Nsight Compute contribute to the analysis process? \n",
      "\n",
      "Output:\n",
      "The rule system in Nsight Compute contributes to the analysis process by providing a structured approach to identifying and analyzing data, ensuring that the analysis is systematic, efficient, and effective. \n",
      "\n",
      "Answer:\n",
      " The rule system in Nsight Compute provides instructions to the profiler for collecting metrics and displaying results, guiding the analysis process by highlighting performance bottlenecks.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_360M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fdebc5-ae11-40ae-8376-1500eb93f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does the rule system in Nsight Compute contribute to the analysis process? \n",
      "\n",
      "Output:\n",
      "The rule system in Nsight Compute contributes to the analysis process by providing a structured approach to data analysis, enabling users to identify patterns, trends, and relationships within large datasets. \n",
      "\n",
      "Answer:\n",
      " The rule system in Nsight Compute provides instructions to the profiler for collecting metrics and displaying results, guiding the analysis process by highlighting performance bottlenecks.\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_1700M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76bbc93-b705-4efa-ac01-82b212524f13",
   "metadata": {},
   "source": [
    "Try with other sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4dbe47b-ed25-4bd7-8dac-790564f53f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25f506f-3636-4e3c-9b47-c7d8f656fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia's mobile workforce is a significant trend that has been gaining momentum in recent years. Here are some ways Nvidia facilitates the transition to a mobile workforce:\n",
      "\n",
      "1. **Cloud-based infrastructure**: Nvidia's cloud-based \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_135M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f466365b-d4b6-4178-9e91-64992500cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia facilitates the transition to a mobile workforce by providing a range of tools and services that enable companies to develop and deploy mobile applications, and by offering a range of cloud-based services that support mobile development and deployment. \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_360M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b744318-18d1-48a8-804c-23f001a82a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia facilitates the transition to a mobile workforce by providing high-performance computing and graphics processing capabilities for mobile devices. \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_1700M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3d757-e171-4b5e-9f31-5a87fb44d8c4",
   "metadata": {},
   "source": [
    "Try with other sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d765d7a-7fa8-4cad-887a-11c5f4a526f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.choice(range(dataset[\"test\"].num_rows))\n",
    "sample = dataset[\"test\"][idx]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "    {\"role\": \"user\", \"content\": \"Answer the question in one sentence.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b590d61-2156-47fd-a7ea-98e20dd7c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia's mobile workforce is a significant trend that has been gaining momentum in recent years. Here are some ways Nvidia facilitates the transition to a mobile workforce:\n",
      "\n",
      "1. **Cloud-based infrastructure**: Nvidia's cloud-based \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_135M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3481ffc6-4832-4544-b713-fa50e0352bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia facilitates the transition to a mobile workforce by providing a range of tools and services that enable companies to develop and deploy mobile applications, and by offering a range of cloud-based services that support mobile development and deployment. \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_360M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aff89e74-49c1-49ec-984b-b12b4730dbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      " How does Nvidia facilitate the transition to a mobile workforce? \n",
      "\n",
      "Output:\n",
      "Nvidia facilitates the transition to a mobile workforce by providing high-performance computing and graphics processing capabilities for mobile devices. \n",
      "\n",
      "Answer:\n",
      " By providing remote desktop solutions and virtual workstations that allow access to powerful applications from anywhere\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe_smol_1700M(\n",
    "    messages,\n",
    "    max_new_tokens=max_new_tokens,\n",
    ")\n",
    "\n",
    "print(\"Question:\\n\",sample[\"question\"],\"\\n\")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"],\"\\n\")\n",
    "\n",
    "print(\"Answer:\\n\",sample[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b9667-fcf0-44d0-833a-5777d4a66cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
